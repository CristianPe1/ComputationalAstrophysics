{"cells":[{"cell_type":"markdown","metadata":{"id":"9mBFEmr745Op"},"source":["![Astrofisica Computacional](https://github.com/ashcat2005/ComputationalAstrophysics/blob/main/logo.png?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"L3hGnt55lxr0"},"source":["---\n","## 01. Logistic Regression Algorithm.\n","\n","\n","Eduard Larrañaga (ealarranaga@unal.edu.co)\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"M5dP3sa345Or"},"source":["\n","### About this notebook\n","\n","In this worksheet, we introduce a Logistic regression algorithm to classify a dataset of stellar features.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"GXWHJYWTlxr0"},"source":["### Linear Regression vs Logistic Regression\n","\n","**Linear Regression** is one of the most simple *supervised regression machine learning algorithm*. In all regression models, the algorithm obtains a target prediction value based on independent variables. They are mostly used for finding out the relationship between variables and forecasting. \n","\n","Different regression models differ based on the kind of relationship between the dependent and independent variables they are considering and in the number of independent variables they consider (Multiple Linear Regression). It  based on the minimization of a cost (error) function, as for example the root mean squared error (minimum squares fit).\n","\n","<img src=\"https://github.com/ashcat2005/ComputationalAstrophysics/blob/main/W05/A/08.%20ML%20II.%20Logistic%20Regression%20(Classification)/LinearRegression.png?raw=1\"  width=600 />\n","\n","The equation obtained form a multiple linear regression has the general form\n","\n","\\begin{equation}\n","y = a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n \n","\\end{equation}\n","\n","\n","\n","---\n","\n","**Logistic Regression** is a *supervised classification machine learning algorithm*. In a classification problem, the target variable (output) can take only discrete values for a given set of features (inputs). For example, logistic regression may be used to predict a target with only two possible values: 0 and 1 or `True` and `False`.\n","\n","<img src=\"https://github.com/ashcat2005/ComputationalAstrophysics/blob/main/W05/A/08.%20ML%20II.%20Logistic%20Regression%20(Classification)/Logistic01.png?raw=1\"  width=600 />\n","\n","\n","Logistic regression is based on the concept of *Maximum Likelihood estimation*. When working with numerical values in logistic regression, we pass the weighted sum of inputs through an activation function that can map values in between 0 and 1. Such activation function is known as **sigmoid function** and the curve obtained is called as sigmoid curve or S-curve.\n","\n","<img src=\"https://github.com/ashcat2005/ComputationalAstrophysics/blob/main/W05/A/08.%20ML%20II.%20Logistic%20Regression%20(Classification)/Logistic02.png?raw=1\"  width=600 />\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p39Cdcehlxr1","outputId":"ba3827de-ede8-4b23-82d4-e3f1510ff0b3","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"ok","timestamp":1683150619872,"user_tz":300,"elapsed":1637,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","\n","def sigmoid(z):\n","    return 1/(1 + np.exp(-z)) \n","\n","zrange = np.linspace(-10,10,50)\n","\n","plt.figure()\n","plt.axhline(0, color='black', alpha=0.3)\n","plt.axvline(0, color='black', alpha=0.3)\n","plt.plot(zrange, sigmoid(zrange), color='crimson')\n","plt.xlabel(r'$z$')\n","plt.ylabel(r'$\\sigma (z)$')\n","plt.grid()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pPPflVBrlxr2"},"source":["\n","\n","---\n","\n","The relation beteween a linear regression and a logistic regression is given by the activation function (sigmoid). In fact, considering the sigmoid functon\n","\n","\\begin{equation}\n","S(z) = \\frac{1}{1+e^{-z}}\n","\\end{equation}\n","\n","and replacing the linear regression equation as $S=y$ and $z = a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n$ we obtain\n","\n","\\begin{align}\n","y = &\\frac{1}{1+e^{-(a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n)}} \\\\\n","\\frac{1}{y} = & 1+e^{-(a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n)}  \\\\\n","\\frac{1}{y} - 1 = & e^{-(a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n)}  \\\\\n","\\log \\left[\\frac{1}{y} - 1\\right] = & -(a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n)  \\\\\n","\\log \\left[\\frac{1-y}{y} \\right] = & -(a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n) \n","\\end{align}\n","\n","Hence, the relation obtained from a  logistic regression is\n","\n","\\begin{equation}\n","\\log \\left[ \\frac{y}{1-y}\\right] = a_0 + a_1 x_1 + a_2 x_2 + ... + a_n x_n\n","\\end{equation}\n"]},{"cell_type":"markdown","metadata":{"id":"gXadA4FK45Ot"},"source":["---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2Qie5Q80lxr3"},"source":["## Stellar Types\n","\n","We will consider a limited dataset taken from [Deepraj Baidya](https://www.kaggle.com/deepu1109) available at\n","\n","[https://www.kaggle.com/datasets/deepu1109/star-dataset](https://www.kaggle.com/datasets/deepu1109/star-dataset)\n","\n","\n","We restrict the dataset to 200 stellar objects (samples) and just three features,\n","\n","- Absolute Temperature [$K$]\n","- Relative Luminosity [$L/L_{\\odot}$]\n","- **Star Type [Non-Main Sequence Star, Main Sequence Star] = [0,1]**\n","\n","where \n","\n","$L_{\\odot} = 3.828 x 10^26$ Watts (Avg Luminosity of Sun)\n","\n","$R_{\\odot} = 6.9551 x 10^8$ m (Avg Radius of Sun).\n","\n","We want to train a logistic classification algorithm that predicts the *Star Type* from the other two features in the dataset."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cBGk0qdl45Os","executionInfo":{"status":"ok","timestamp":1683150619873,"user_tz":300,"elapsed":19,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","%matplotlib inline"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":341,"status":"error","timestamp":1683150809563,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"},"user_tz":300},"id":"X7wLEZjO45Ot","outputId":"2d32c0f7-78a8-45dd-dc88-242e5c551c4b"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-fd8739c291d4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HRData.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HRData.csv'"]}],"source":["df = pd.read_csv('HRData.csv')\n","df"]},{"cell_type":"markdown","metadata":{"id":"34DMi7lPlxr4"},"source":["This data can be used to obtain the Hertzprung-Rusell diagram,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxDn8e58lxr4","executionInfo":{"status":"aborted","timestamp":1683150619875,"user_tz":300,"elapsed":16,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["colors = {0:'cornflowerblue' , 1:'crimson'}\n","\n","plt.style.use('dark_background')\n","plt.figure(figsize=(6,8))\n","plt.scatter(df['Temperature (K)'], df['Luminosity(L/Lo)'], marker='.',\n","            c = [colors[i] for i in df['Star type']],\n","            s=20)\n","\n","plt.xlim(45000,0)\n","plt.yscale('log')\n","plt.xlabel(r'Temperature [$K$]')\n","plt.ylabel(r'Luminosity [$L/L_{\\odot}$]')\n","plt.title('HR-Diagram')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TeD61k_Jlxr5"},"source":["The red points are **Main sequence** stars while the blue points are either **supergiant** or **hypergiant** stars. We want to predict this classification using the temperature and the luminosity."]},{"cell_type":"markdown","metadata":{"id":"shIrNhzclxr5"},"source":["---\n","## Peparing the data\n","\n","We will train a **Logistic Classification** algorithm using this information. The first step is to define the dependent and independent variables,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpFHSYVslxr5","executionInfo":{"status":"aborted","timestamp":1683150619875,"user_tz":300,"elapsed":16,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["X = np.asarray(df[['Temperature (K)','Luminosity(L/Lo)']])\n","y = np.asarray(df[['Star type']], dtype=int)\n","\n","X.shape, y.shape"]},{"cell_type":"markdown","metadata":{"id":"9KTGISBulxr6"},"source":["Now, we will split this set into train and test subsets, using the function [sk.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RutgU-clxr6","executionInfo":{"status":"aborted","timestamp":1683150619876,"user_tz":300,"elapsed":17,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=413, test_size=0.2)\n","\n","print(\"Shape of X_train : \", X_train.shape)\n","print(\"Shape of Y_train : \", y_train.shape)\n","print(\"Shape of X_test : \", X_test.shape)\n","print(\"Shape of Y_test : \", y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"GSGjHxku45Oy"},"source":["## Logistic Regression\n","\n","We will implement a **Logistic Regression** (binary classification) algorithm from scratch. We will use a fit function with the form\n","\n","\\begin{equation}\n","y_p (x;W,b) = \\sigma (z(x;W,b)) \n","\\end{equation}\n","\n","where $\\sigma (z)$ represents the sigmoid (logistic) function,\n","\n","\\begin{equation}\n","\\sigma (z) = \\frac{1}{1+e^{-z}} \n","\\end{equation}\n","\n","and $z(x;W,b) = Wx + b$. Therefore, we have\n","\n","\\begin{equation}\n","y_p (x;W,b) = \\frac{1}{1+e^{-(Wx + b)}}. \n","\\end{equation}\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gY1icAuRlxr6"},"source":["## The Cost Function\n","\n","Since the result of the regression will be a binary classification, with values 0 or 1, the cost function cannot have the form\n","\n","\\begin{equation}\n","f_{c} = \\frac{1}{n} \\sum_{i=1}^n \\left( y_{p}(x_i) - y_i \\right)^2.\n","\\end{equation}\n","\n","\n","In order to define the correct cost function, consider the following probabilities:\n","\n","- Probability to obtain a result of $y_i = 1$ for a given input $x_i$,\n","\n","\\begin{equation}\n","P(y_i = 1| x_i ; W,b) = \\frac{1}{1 + \\exp \\left[-\\left( W x_i + b \\right)\\right]}\n","\\end{equation}\n","\n","- Probability to obtain a result of $y_i = 0$ for a given input $x_i$,\n","\n","\\begin{equation}\n","P(y_i = 0| x_i ; W,b) = 1 - P(y_i = 1| x_i ; W,b).\n","\\end{equation}\n","\n","\n","### Maximum Likelihood\n","\n","In general, given all possible outcomes from a dataset $D = \\{ (x_i, y_i) \\}$ with the binary labels $y_i \\in \\{0,1\\}$, where the data points are drawn independently, it is used the **M**aximum **L**ikelihood **E**stimation (**MLE**) principle. It states that we need to maximize the probability of seen the observed data and this can be written as the product od the individual probabilities of a specific outcome $y_i$, i.e.\n","\n","\\begin{align}\n","P(D ; W,b) = &\\prod _{i=1}^n \\left[ P(y_i=1 | x_i ; W,b) \\right]^{y_i} \\left[ P(y_i=0 | x_i ; W,b) \\right]^{1-y_i}\\\\\n","P(D ; W,b) = &\\prod _{i=1}^n \\left[ P(y_i=1 | x_i ; W,b) \\right]^{y_i} \\left[ 1- P(y_i=1 | x_i ; W,b) \\right]^{1-y_i}\n","\\end{align}\n","\n","Taking the logarithm of this probability, we obtain the (log-likelihood) cost as\n","\n","\\begin{equation}\n","C (W,b) = \\sum _{i=1}^n  \\left\\{ y_i \\left[\\log P(y_i=1 | x_i ; W,b) \\right] + (1-y_i) \\log \\left[ 1- P(y_i=1 | x_i ; W,b) \\right] \\right\\}.\n","\\end{equation}\n","\n","Then, we will define a cost function as\n","\n","\\begin{equation}\n","f_{c} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(y_p (x_i)) + (1-y_i)\\log (1-y_p(x_i)) \\right]\n","\\end{equation}\n","\n","where we included a minus sign in order to obtain a function that must be minimized. Note that this cost function implies that:\n","\n","- For a sigle sample with target value $y_i = 0$, the cost function reduces to $f_{c} = - \\log (1-y_p)$. Note that a prediction near $y_p \\sim 1$ gives a huge cost, $f_c \\rightarrow \\infty$, while a prediction near $y_p \\sim y_0 = 0$ gives a low cost, $f_c \\rightarrow 0$.\n","\n","- For a sigle sample with target value $y_i = 1$, the cost function reduces to $f_{c} = - \\log (y_p)$. This time, a prediction of $y_p \\sim 0$ gives a huge cost, $f_c \\rightarrow \\infty$, while a prediction of $y_p \\sim y_0 = 1$ gives a low cost, $f_c \\rightarrow 0$.\n","\n","$f_c (W,b)$ is known in statistics as the **cross entropy** for two density functions $y$ and $y_p$. In a future lecture we will study the entropy and cross entropy in detail.\n","\n","\n","### Gradient of the Cost Function\n","The gradient of the cost function, w.r.t. the parameters $W$ and $b$ give\n","\\begin{align}\n","\\frac{ \\partial f_{c}}{\\partial W} = &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p} \\frac{ \\partial y_p}{\\partial W} - \\frac{1-y_i}{1-y_p} \\frac{ \\partial y_p}{\\partial W} \\right] \\\\ \n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p}  - \\frac{1-y_i}{1-y_p}  \\right]\\left( y_p (1 -y_p) x_i \\right) \\\\\n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i(1 -y_p) - (1-y_i) y_p  \\right] x_i\\\\\n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i -  y_p  \\right] x_i\\\\\n","= & \\frac{1}{n} \\sum_{i=1}^n \\left[ y_p -  y_i  \\right] x_i.\n","\\end{align}\n","\n","and \n","\n","\\begin{align}\n","\\frac{ \\partial f_{c}}{\\partial b} = &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p} \\frac{ \\partial y_p}{\\partial b} - \\frac{1-y_i}{1-y_p} \\frac{ \\partial y_p}{\\partial b} \\right] \\\\ \n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p}  - \\frac{1-y_i}{1-y_p}  \\right]\\left( y_p (1 -y_p)\\right) \\\\\n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i(1 -y_p) - (1-y_i) y_p  \\right] \\\\\n","= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i -  y_p  \\right] \\\\\n","= & \\frac{1}{n} \\sum_{i=1}^n \\left[ y_p -  y_i  \\right].\n","\\end{align}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbS7g_0Zlxr7","executionInfo":{"status":"aborted","timestamp":1683150619877,"user_tz":300,"elapsed":17,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["class LogisticRegression():\n","    '''\n","    Logistic regression class\n","    '''\n","    def __init__(self):\n","        pass\n","    \n","    def sigmoid(self, Z):\n","        return 1/(1 + np.exp(-Z))\n","\n","    def Z(self, X):\n","        '''\n","        Function to fit\n","        '''\n","        return self.b + np.dot(X,self.W)\n","    \n","    def predict(self, X):\n","        '''\n","        Predict method\n","        '''\n","        yp = self.sigmoid(self.Z(X))\n","        #yp = yp > 0.5\n","        return yp\n","    \n","    def cost(self, X, y):\n","        '''\n","        Cost function\n","        '''\n","        Yp = self.predict(X)\n","        return -(1/self.n)*np.sum(y*np.log(Yp) + (1-y)*np.log(1-Yp))\n","    \n","    def grad_cost(self, X,y):\n","        '''\n","        Analytic gradient of the cost function\n","        '''\n","        Yp = self.predict(X)\n","        grad_dW = (1/self.n)*np.dot(X.T, Yp-y)\n","        grad_db = (1/self.n)*np.sum(Yp-y)\n","        return grad_dW, grad_db\n","    \n","    def fit(self, X, y, alpha= 0.01):\n","        '''\n","        Optimization function\n","        '''\n","        # alpha : Learning rate\n","        tol = 1e-10    # Tolerance\n","        #np.random.seed(413)\n","        self.m = X.shape[1] # Number of features\n","        self.n = X.shape[0] # Number od samples\n","        \n","        self.W = np.zeros([self.m,1])#np.random.rand(self.m)\n","        self.b = 0#np.random.rand(1)\n","        Y = self.sigmoid(self.Z(X))\n","\n","        self.history = []\n","        self.history.append(self.cost(X, y))\n","        print('Initial cost = ', self.history[0])\n","        \n","        epoch = 0 # Epochs\n","        epsilon = 1\n","        while epsilon>tol and epoch<900000:\n","            # Gradient\n","            grad_dW, grad_db = self.grad_cost(X,y)\n","\n","            self.W = self.W - alpha*grad_dW\n","            self.b = self.b - alpha*grad_db\n","            \n","            self.history.append(self.cost(X, y))\n","            epsilon = abs(self.history[epoch] - self.history[epoch+1])\n","            epoch +=1\n","        \n","        print('Final cost = ', self.history[-1])\n","        print('Number of epochs = ',epoch)\n","    \n","    def accuracy(self, X, y):\n","        '''\n","        Calculates the accuracy of the algorithm\n","        as the percentage of succesful predictions\n","        '''\n","        Yp = self.predict(X)\n","        Yp = Yp > 0.5\n","        Yp = np.array(Yp, dtype = 'int64')\n","        acc = (1 - np.sum(abs(Yp - y))/len(y))*100\n","        print(\"Accuracy of the model is : \", round(acc, 2), \"%\")\n","        \n","    "]},{"cell_type":"markdown","metadata":{"id":"0K7S4otnlxr8"},"source":["We train the model using the presented data,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5Mgue4hlxr8","executionInfo":{"status":"aborted","timestamp":1683150619878,"user_tz":300,"elapsed":18,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["lr = LogisticRegression()\n","\n","lr.fit(X_train, y_train)\n","\n","print('\\nThe optimized parameters are')\n","print('W = ', lr.W)\n","print('b = ', lr.b)"]},{"cell_type":"markdown","metadata":{"id":"P7qgRYxilxr8"},"source":["Note that the algorithm is not trained because the cost function diverges after one epoch. The reason is the big values in the Temperature and Luminosity features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNoVQImwlxr8","executionInfo":{"status":"aborted","timestamp":1683150619879,"user_tz":300,"elapsed":19,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"EmNSjm0nlxr9"},"source":["### Scaling the Data\n","\n","In order to obtain a good training of the logistic regression algorithm, we will scale the input features.\n","\n","[Scikit-Learn](https://scikit-learn.org/stable/index.html) has several functions which allow us to rescale the data, normally resulting in much better results in terms of various accuracy scores. \n","\n","* The [scikitlearn.preprocessing.StandardScaler( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) function standardize features by removing the mean and scaling to unit variance. This ensures that for each feature we study the mean value is zero and the variance is one. This scaling has the drawback that it does not ensure that we have a particular maximum or minimum in our data set. \n","\n","* The function  [scikitlearn.preprocessing.MinMaxScaler( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) ensures that all features are exactly between 0 and 1.\n","\n","* The [scikitlearn.preprocessing.Normalizer( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html function scales each data point such that the feature vector has a euclidean length of one. In other words, it projects a data point on the circle (or sphere in the case of higher dimensions) with a radius of 1. This means every data point is scaled by a different number (by the inverse of it’s length). This normalization is often used when only the direction (or angle) of the data matters, not the length of the feature vector.\n","\n","* The [scikitlearn.preprocessing.RobustScaler( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)  works similarly to the StandardScaler in that it ensures statistical properties for each feature that guarantee that they are on the same scale. However, the RobustScaler uses the median and quartiles, instead of mean and variance. This makes the RobustScaler ignore data points that are very different from the rest (like measurement errors). These odd data points are also called **outliers**, and might often lead to trouble for other scaling techniques.\n","\n","\n","We will try first the StandardScaler function,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckA2vxvllxr9","executionInfo":{"status":"aborted","timestamp":1683150619879,"user_tz":300,"elapsed":19,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler_train = StandardScaler()\n","scaler_train.fit(X_train)\n","\n","scaler_test = StandardScaler()\n","scaler_test.fit(X_test)\n","\n","X_train_scaled = scaler_train.transform(X_train)\n","X_test_scaled = scaler_test.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"0SJmQ7Splxr9"},"source":["Compare the first ten element in the original and scaled sets, "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48vzpS8glxr9","executionInfo":{"status":"aborted","timestamp":1683150619880,"user_tz":300,"elapsed":19,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["X_test[:10], X_test_scaled[:10]"]},{"cell_type":"markdown","metadata":{"id":"aMSrSyTBlxr-"},"source":["Now we train the alogorithm using the scaled data,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8EwWakslxr-","executionInfo":{"status":"aborted","timestamp":1683150619882,"user_tz":300,"elapsed":21,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["lr = LogisticRegression()\n","\n","lr.fit(X_train_scaled, y_train, alpha=0.1)\n","\n","print('\\nThe optimized parameters are')\n","print('W = ',lr.W)\n","print('b = ',lr.b)"]},{"cell_type":"markdown","metadata":{"id":"XkZARnXjlxr-"},"source":["After 900000 epochs, with a learning rate of 0.1, the value of the cost function is 0.012. \n","The accuracy method for the train set gives"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6tftpualxr-","executionInfo":{"status":"aborted","timestamp":1683150619883,"user_tz":300,"elapsed":22,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["lr.accuracy(X_train_scaled, y_train)"]},{"cell_type":"markdown","metadata":{"id":"lISuogDflxr-"},"source":["While the accuracy for the test set is"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eirsLS1Slxr_","executionInfo":{"status":"aborted","timestamp":1683150619883,"user_tz":300,"elapsed":22,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["lr.accuracy(X_test_scaled, y_test)"]},{"cell_type":"markdown","metadata":{"id":"57ld9qv8lxr_"},"source":["The training history shows the behavior of the cost function during the epochs,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opBxEMpdlxr_","executionInfo":{"status":"aborted","timestamp":1683150619884,"user_tz":300,"elapsed":23,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["# Plot Training history\n","plt.style.use('default')\n","plt.figure()\n","plt.plot(lr.history, color='crimson')\n","plt.ylabel(r'cost function')\n","plt.xlabel(r'epoch')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"6CsD2YLhlxr_"},"source":["An interesting form to illustrate the score of a logistic model is using the [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) in which we present the predictions and the target labels,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vO8kVM07lxr_","executionInfo":{"status":"aborted","timestamp":1683150619885,"user_tz":300,"elapsed":24,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["def confusion_matrix(X,y):\n","    yp = lr.predict(X)\n","    yp = yp>0.5\n","    yp = np.array(yp, dtype = 'int64')\n","    cm = np.array([[0,0],[0,0]])\n","    for i in range(len(y)):\n","        # MS prediction and MS target\n","        if yp[i]==1 and y[i]==1:\n","            cm[1,1] +=1\n","        # Non-MS prediction and MS target\n","        if yp[i]==0 and y[i]==1:\n","            cm[1,0] +=1\n","        # MS prediction and Non-MS target\n","        if yp[i]==1 and y[i]==0:\n","            cm[0,1] +=1\n","        # Non-MS prediction and Non-MS target\n","        if yp[i]==0 and y[i]==0:\n","            cm[0,0] +=1\n","    cm = cm/len(y)\n","    return cm \n","\n","\n","cm = confusion_matrix(X_test_scaled, y_test)\n","cm"]},{"cell_type":"markdown","metadata":{"id":"dBgSi22rlxsA"},"source":["Graphically, the confusion matrix is"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IbbcnSblxsA","executionInfo":{"status":"aborted","timestamp":1683150619886,"user_tz":300,"elapsed":24,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["# Plot the Confusion-Matrix\n","plt.figure(figsize=(5,5))\n","plt.imshow(cm, extent=(0,1,0,1))\n","plt.xticks(ticks=[0.25,0.75], labels=('Non-Main Seq', 'Main Seq'))\n","plt.yticks(ticks=[0.25,0.75], labels=('Main Seq','Non-Main Seq'))\n","plt.xlabel('Predicted Label')\n","plt.ylabel('Target Label')\n","plt.text(0.25, 0.75, cm[0,0], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.75, 0.75, cm[0,1], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.25, 0.25, cm[1,0], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.75, 0.25, cm[1,1], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"m0CsvyqWlxsA"},"source":["For comparison, a perfect prediction will give the following confusion matrix,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxu58vjnlxsA","executionInfo":{"status":"aborted","timestamp":1683150619886,"user_tz":300,"elapsed":24,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["# Perfect Predictions Confusion-Matrix\n","\n","def confusion_matrix2(yp,y):\n","    cm = np.array([[0,0],[0,0]])\n","    for i in range(len(y)):\n","        # MS prediction and MS target\n","        if yp[i]==1 and y[i]==1:\n","            cm[1,1] +=1\n","        # Non-MS prediction and MS target\n","        if yp[i]==0 and y[i]==1:\n","            cm[1,0] +=1\n","        # MS prediction and Non-MS target\n","        if yp[i]==1 and y[i]==0:\n","            cm[0,1] +=1\n","        # Non-MS prediction and Non-MS target\n","        if yp[i]==0 and y[i]==0:\n","            cm[0,0] +=1\n","    cm = cm/len(y)\n","    return cm \n","\n","\n","cmperf = confusion_matrix2(y_test, y_test)\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(cmperf, extent=(0,1,0,1))\n","plt.xticks(ticks=[0.25,0.75], labels=('Non-Main Seq','Main Seq'))\n","plt.yticks(ticks=[0.25,0.75], labels=('Main Seq','Non-Main Seq'))\n","plt.xlabel('Predicted Label')\n","plt.ylabel('Target Label')\n","plt.text(0.25, 0.75, cmperf[0,0], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.75, 0.75, cmperf[0,1], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.25, 0.25, cmperf[1,0], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.text(0.75, 0.25, cmperf[1,1], color='white',horizontalalignment='center',verticalalignment='center')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mHseVaV3lxsB"},"source":["The same result is obtained by using the functions [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) and  [sklearn.metrics.ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZpb2wJrlxsB","executionInfo":{"status":"aborted","timestamp":1683150619886,"user_tz":300,"elapsed":24,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","prediction = lr.predict(X_test_scaled)\n","prediction = prediction > 0.5\n","prediction = np.array(prediction, dtype = 'int64')\n","\n","cm = confusion_matrix(y_test, prediction, normalize='all')\n","print(cm)\n","\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nG15p9TClxsB","executionInfo":{"status":"aborted","timestamp":1683150619887,"user_tz":300,"elapsed":25,"user":{"displayName":"Cristian Esteban Pena Velandia","userId":"11368640312585175379"}}},"outputs":[],"source":[]}],"metadata":{"@webio":{"lastCommId":null,"lastKernelId":null},"colab":{"provenance":[{"file_id":"https://github.com/ashcat2005/ComputationalAstrophysics/blob/main/W05/A/08.%20ML%20II.%20Logistic%20Regression%20(Classification)/01.%20Logistic%20Regression%20Algorithm.ipynb","timestamp":1683150596836}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}